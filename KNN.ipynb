{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_distance(vec_1,vec_2):\n",
    "    diff_vec = vec_1-vec_2\n",
    "    sum_squares = diff_vec**2\n",
    "    return sum_squares.sum()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class KNN_classifier:\n",
    "    def __init__(self, n_neighbors: int, **kwargs):\n",
    "        self.K = n_neighbors\n",
    "\n",
    "    def fit(self, x: np.array, y: np.array):\n",
    "        # TODO: напишите метод .fit() класса KNN_classifier\n",
    "        # Эта функция принимает на вход два массива:\n",
    "        # - x (набор признаков, массив размерности n x m, n - число объектов, m - размерность признакового описания)\n",
    "        # - y (метки для обучения, одномерный массив размерности n)\n",
    "        # Эта функция ничего не возвращает, она должна настроить внутренние параметры модели для дальнейшего использования\n",
    "        # Подумайте, в чем заключается процесс обучения именно этого алгоритма?\n",
    "        # Что этот алгоритм делает в тот момент, когда он получил обучающую выборку?\n",
    "        # Реализуйте эту логику в коде\n",
    "        pass\n",
    "\n",
    "    def predict(self, x: np.array):\n",
    "        predictions = []\n",
    "        # TODO: напишите метод .predict(x) класса KNN_classifier\n",
    "        # Этот метод принимает на вход один массив x. Массив x - это двумерный массив объектов, для которых требуется получить предсказание\n",
    "        # На выходе этой функции мы хотим получить одномерный массив predictions, размерности x.shape[0] (то есть для каждогго объекта массива x мы сделали своё предсказание)\n",
    "        # Вспомните, как алгоритм KNN делает предсказание?\n",
    "        # Реализуйте эту логику в коде\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_classifier:\n",
    "    def __init__(self, n_neighbors: int, **kwargs):\n",
    "        self.K = n_neighbors\n",
    "\n",
    "    def fit(self, x: np.array, y: np.array):\n",
    "        self.x_train = x\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, x: np.array):\n",
    "        predictions = [None for i in range(len(x))]\n",
    "        for i in range(len(x)):\n",
    "            distances = sorted(self.x_train,key=lambda y: euc_distance(y,x[i]))\n",
    "            best_n = distances[:self.K]\n",
    "            classes_scores  = {key:0 for key in list(set(self.y_train))}\n",
    "            for j in range(len(best_n)):\n",
    "                classes_scores[self.y_train[j]]+=1\n",
    "            best_result = 0\n",
    "            best_class = None\n",
    "            for a,b in classes_scores.items():\n",
    "                if b>best_result:\n",
    "                    best_result = b\n",
    "                    best_class = a\n",
    "            predictions[i] = best_class\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.array([1,2,1])\n",
    "p = [None for i in range(len(k))]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 0.56510722,  0.68599596, -0.92388505, -0.29546048, -0.12437532],\n",
    "       [-0.79617537,  0.98406791,  1.19542652, -0.05626863, -0.69868076],\n",
    "       [ 0.9629688 , -1.00423925, -0.53842833, -0.23744358,  0.83226685],\n",
    "       [ 0.24671269, -0.41624448,  0.81679337,  1.59227446,  0.16192583],\n",
    "       [-0.36972363,  0.17425997,  1.33668078,  1.16687907,  0.31709134],\n",
    "       [-1.30482844, -0.05354323, -0.88862186, -1.121785  , -0.78442809],\n",
    "       [-0.53975018,  0.90074877, -1.09317408,  1.52989481, -0.43375015],\n",
    "       [-0.64709803, -0.09775791,  1.3506503 , -1.46957788,  1.63325543],\n",
    "       [-0.73858464, -0.60678229,  0.31420272, -0.43100129, -0.37665876],\n",
    "       [-0.29208809, -0.68795722,  0.06586655,  0.9583851 ,  1.70640775]])\n",
    "y = np.array([1, 0, 0, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN_classifier(n_neighbors=3)\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([[-0.12489725,  0.65791923, -0.73112495,  1.42660225,  1.64728976],\n",
    "       [ 0.01913388, -1.11351208, -0.63244098, -0.98121107,  0.38060892],\n",
    "       [-0.92074931,  1.39812225,  0.39692147,  0.7717827 ,  0.44604002]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([1, 0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
